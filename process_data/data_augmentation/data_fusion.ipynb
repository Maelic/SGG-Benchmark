{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code will merge the data transfer obtained after running ietrans.py to a new .h5 file containing the augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transfer:  99824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108073/108073 [00:29<00:00, 3654.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After transfer:  133908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_path = \"../../datasets/IndoorVG_4/VG-SGG.h5\"\n",
    "new_rels_path = \"./ietrans_vctree.json\"\n",
    "dict_path = \"../../datasets/IndoorVG_4/VG-SGG-dicts.json\"\n",
    "img_data_path = \"../../datasets/vg/image_data.json\"\n",
    "img_data = json.load(open(img_data_path, 'r'))\n",
    "\n",
    "data = h5py.File(data_path, 'r')\n",
    "new_rels_data = json.load(open(new_rels_path, 'r'))\n",
    "labels_dict = json.load(open(dict_path, 'r'))\n",
    "\n",
    "idx_to_labels = labels_dict['idx_to_label']\n",
    "idx_to_predicates = labels_dict['idx_to_predicate']\n",
    "\n",
    "relationships = []\n",
    "predicates = []\n",
    "im_to_first_rel = np.zeros(len(data['img_to_first_rel']), dtype=np.int32)\n",
    "im_to_last_rel = np.zeros(len(data['img_to_first_rel']), dtype=np.int32)\n",
    "\n",
    "rel_idx_counter = 0\n",
    "\n",
    "print('Before transfer: ', len(data['relationships']))\n",
    "\n",
    "data_split = data['split_rel'][:]\n",
    "split_mask = data_split == 0\n",
    "split_mask &= data['img_to_first_rel'][:] >= 0\n",
    "image_index = np.where(split_mask)[0]\n",
    "\n",
    "count_trans = 0\n",
    "out_count = 0\n",
    "orig_img = 0\n",
    "for i in tqdm(range(len(data['split_rel']))):\n",
    "    image_name = str(img_data[i]['image_id'])+'.jpg'\n",
    "    if (str(image_name) not in new_rels_data.keys()) or len(new_rels_data[str(image_name)]) == 0:\n",
    "        orig_img +=1\n",
    "        im_to_first_rel[i] = rel_idx_counter\n",
    "        if data['img_to_first_rel'][i] == -1:\n",
    "            im_to_first_rel[i] = -1\n",
    "            im_to_last_rel[i] = -1\n",
    "        else:\n",
    "            for j in range(data['img_to_first_rel'][i], data['img_to_last_rel'][i]+1):\n",
    "                predicates.append(data['predicates'][j])\n",
    "                relationships.append(data['relationships'][j])\n",
    "                rel_idx_counter += 1\n",
    "                out_count += 1\n",
    "            im_to_last_rel[i] = rel_idx_counter - 1\n",
    "    else:\n",
    "        new_rels = new_rels_data[str(image_name)]\n",
    "        im_to_first_rel[i] = rel_idx_counter\n",
    "        # internal trans\n",
    "        if data['img_to_first_rel'][i] != -1:\n",
    "            for j in range(data['img_to_first_rel'][i], data['img_to_last_rel'][i]+1):\n",
    "                r = data['relationships'][j]\n",
    "                rel = [r[0]-data['img_to_first_box'][i], r[1]-data['img_to_first_box'][i]]\n",
    "                if len(new_rels) != 0 and np.any(np.all(np.array(new_rels)[:,0:2] == rel, axis=1)):\n",
    "                    rel_idx = np.where(np.all(np.array(new_rels)[:,0:2] == rel, axis=1))[0]\n",
    "                    # print('Found: ', rel, new_rels[rel_idx[0]])\n",
    "                    # print('old: ', data['predicates'][j], 'new: ', new_rels[rel_idx[0]][2])\n",
    "                    predicates.append([new_rels[rel_idx[0]][2]])\n",
    "                    new_rels.pop(rel_idx[0])\n",
    "                else:\n",
    "                    out_count += 1\n",
    "                    predicates.append(data['predicates'][j])\n",
    "                rel_idx_counter += 1\n",
    "                relationships.append(r)\n",
    "        # external trans\n",
    "        for rel in new_rels:\n",
    "            i_obj_start = data['img_to_first_box'][i]\n",
    "            num_boxes = data['img_to_last_box'][i] - i_obj_start + 1\n",
    "            sub = i_obj_start + rel[0]\n",
    "            obj = i_obj_start + rel[1]\n",
    "\n",
    "            if rel[0] >= num_boxes or rel[1] >= num_boxes:\n",
    "                print('Error: ', rel[0], rel[1], num_boxes)\n",
    "                continue\n",
    "\n",
    "            predicates.append(rel[2])\n",
    "            relationships.append([sub,obj])\n",
    "            rel_idx_counter += 1\n",
    "            count_trans += 1\n",
    "        if im_to_first_rel[i] == rel_idx_counter:\n",
    "        # if no qualifying relationship\n",
    "            im_to_first_rel[i] = -1\n",
    "            im_to_last_rel[i] = -1\n",
    "        else:\n",
    "            im_to_last_rel[i] = rel_idx_counter - 1\n",
    "\n",
    "print('After transfer: ', len(relationships))\n",
    "\n",
    "assert len(predicates) == len(relationships)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133908, 2)\n"
     ]
    }
   ],
   "source": [
    "out_path = \"../../datasets/IndoorVG_4/VG-SGG-augmented-vctree.h5\"\n",
    "\n",
    "f = h5py.File(out_path, 'w')\n",
    "\n",
    "predicates = np.vstack(predicates)\n",
    "relationships = np.vstack(relationships)\n",
    "\n",
    "f.create_dataset('labels', data=data['labels'])\n",
    "f.create_dataset('boxes_512', data=data['boxes_512'])\n",
    "f.create_dataset('boxes_1024', data=data['boxes_1024'])\n",
    "\n",
    "f.create_dataset('img_to_first_box', data=data['img_to_first_box'])\n",
    "f.create_dataset('img_to_last_box', data=data['img_to_last_box'])\n",
    "\n",
    "f.create_dataset('predicates', data=predicates)\n",
    "f.create_dataset('relationships', data=relationships)\n",
    "f.create_dataset('img_to_first_rel', data=im_to_first_rel)\n",
    "f.create_dataset('img_to_last_rel', data=im_to_last_rel)\n",
    "\n",
    "f.create_dataset('split_rel', data=data['split_rel'])\n",
    "f.create_dataset('split', data=data['split'])\n",
    "\n",
    "# open h5 file\n",
    "f.close()\n",
    "\n",
    "data = h5py.File(out_path, 'r')\n",
    "print(data['relationships'].shape)\n",
    "data.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
