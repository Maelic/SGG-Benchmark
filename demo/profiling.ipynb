{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-09 18:50:36.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msgg_benchmark.utils.logger\u001b[0m:\u001b[36msetup_logger\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mUsing loguru logger with level: INFO\u001b[0m\n",
      "Overriding model.yaml nc=80 with nc=84\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3824332  ultralytics.nn.modules.head.Detect           [84, [192, 384, 576]]         \n",
      "YOLOv8m summary: 295 layers, 25904956 parameters, 25904940 gradients, 79.3 GFLOPs\n",
      "\n",
      "loading word vectors from /home/maelic/glove/glove.6B.200d.pt\n",
      "loading word vectors from /home/maelic/glove/glove.6B.200d.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-04-09 18:50:39 947026:947026 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-04-09 18:50:39 947026:947026 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-04-09 18:50:39 947026:947026 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.028138160705566406\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        20.04%       6.387ms        88.56%      28.228ms      28.228ms       0.000us         0.00%      22.143ms      22.143ms             1  \n",
      "                                           aten::conv2d         1.30%     415.000us        14.50%       4.620ms      51.910us       0.000us         0.00%       9.594ms     107.798us            89  \n",
      "                                      aten::convolution         0.95%     302.000us        13.88%       4.425ms      49.719us       0.000us         0.00%       9.872ms     110.921us            89  \n",
      "                                     aten::_convolution         1.23%     391.000us        13.05%       4.161ms      46.753us       0.000us         0.00%      10.019ms     112.573us            89  \n",
      "                                            aten::copy_         0.52%     166.000us        11.63%       3.706ms     102.944us     106.000us         0.48%     106.000us       2.944us            36  \n",
      "                                aten::cudnn_convolution         8.34%       2.659ms        11.53%       3.676ms      41.303us       9.787ms        44.20%       9.787ms     109.966us            89  \n",
      "                                  cudaDeviceSynchronize        11.44%       3.645ms        11.44%       3.645ms       3.645ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.15%      47.000us        11.43%       3.643ms     113.844us       0.000us         0.00%      23.000us       0.719us            32  \n",
      "                                         aten::_to_copy         0.17%      55.000us        11.38%       3.627ms     201.500us       0.000us         0.00%      26.000us       1.444us            18  \n",
      "                                       aten::index_put_         0.05%      15.000us        10.99%       3.504ms     438.000us       0.000us         0.00%      13.000us       1.625us             8  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 31.873ms\n",
      "Self CUDA time total: 22.143ms\n",
      "\n",
      "Number of parameters: 171628072\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from demo_model import SGG_Model\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "config_path = \"/home/maelic/ros2_humble/src/Robots-Scene-Understanding/rsu_scene_graph_generation/models/penet-yolov8m/config.yaml\"\n",
    "dict_path = \"../datasets/IndoorVG_4/VG-SGG-dicts.json\"\n",
    "\n",
    "example_img = \"./test_custom/example.jpg\"\n",
    "# load image with cv2\n",
    "img = cv2.imread(example_img)\n",
    "\n",
    "model = SGG_Model(config_path, dict_path)\n",
    "img_list, target = model._pre_processing(img)\n",
    "targets = [target.to(model.device)]\n",
    "img_list = img_list.to(model.device)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        time_start = time.time()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs, features = model.model.backbone(img_list.tensors, embed=True)\n",
    "            proposals = model.model.backbone.postprocess(outputs, img_list.image_sizes)\n",
    "\n",
    "            _, predictions, _ = model.model.roi_heads(features, proposals, targets, None, proposals)\n",
    "\n",
    "        time_end = time.time()\n",
    "print(f\"Time: {time_end - time_start}\")\n",
    "#predictions = model._post_process_yolo(predictions[0], orig_size=img_list.image_sizes[0])\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of full model: 171628072\n",
      "Number of parameters of backbone: 25904956\n",
      "Number of parameters of Relation head: 145723116\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "print(f\"Number of parameters of full model: {total_params}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.model.backbone.parameters())\n",
    "print(f\"Number of parameters of backbone: {total_params}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.model.roi_heads.parameters())\n",
    "print(f\"Number of parameters of Relation head: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from demo_model import SGG_Model\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "config_path = \"./checkpoints/IndoorVG4/SGDET/penet-faster_rcnn/config.yml\"\n",
    "dict_path = \"../datasets/IndoorVG/VG-SGG-dicts.json\"\n",
    "\n",
    "example_img = \"./test_custom/example.jpg\"\n",
    "# load image with cv2\n",
    "img = cv2.imread(example_img)\n",
    "\n",
    "model = SGG_Model(config_path, dict_path)\n",
    "img_list, target = model._pre_processing(img)\n",
    "target = torch.LongTensor([-1])\n",
    "targets = [target.to(model.device)]\n",
    "img_list = img_list.to(model.device)\n",
    "model.model.eval()\n",
    "\n",
    "# warm-up\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        time_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "            # for i in range(10):\n",
    "            features = model.model.backbone(img_list.tensors)\n",
    "            proposals, proposal_losses = model.model.rpn(img_list, features, targets)\n",
    "            x, result, detector_losses = model.model.roi_heads(features, proposals, targets)\n",
    "            # del x, result, detector_losses\n",
    "            torch.cuda.empty_cache()\n",
    "            print(time.time() - time_start)\n",
    "        time_end = time.time()\n",
    "print(f\"Time: {(time_end - time_start)/10}\")\n",
    "#predictions = model._post_process_yolo(predictions[0], orig_size=img_list.image_sizes[0])\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
